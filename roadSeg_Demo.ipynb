{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78d123a1",
   "metadata": {},
   "source": [
    "# This file gives an example to do road segmentation in satellite images\n",
    "\n",
    "## Download the image data from MASS dataset\n",
    "\n",
    "\n",
    "Note: Test the code on other dataset, need to save the trainX, trainY, testX, testY image data into four file directories: '../data/xxx/yyyy/' respectively. where 'xxx' is your dataset name, 'yyyy' is 'trainX', 'trainY', 'testX', 'testY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4064e8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#python3.9 downloadMASS.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae13ec7",
   "metadata": {},
   "source": [
    "## Step 1 Import and definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cf46cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./source/') \n",
    "import source.genSamples as genS\n",
    "import source.segmentor as seg\n",
    "import networks as nt #User can define new network in networks.py file\n",
    "import utils as ut\n",
    "import time\n",
    "\n",
    "rootDir = './'\n",
    "sID = 0 #The number of test (all saved files are related to this number)\n",
    "dataset = 'MASS'\n",
    "\n",
    "sampleSize = 512 #the training sample size: sampleSize * sampleSize\n",
    "alpha = '005'#0xx: 0.xx, threshold to select key pixels for preparing training sample in stage 2\n",
    "ap = list(alpha); ap.insert(1,'.'); \n",
    "delta = float(''.join(ap))\n",
    "\n",
    "network1 = 'dinknet34' #select network\n",
    "lossSel1 = 'DBCE' #select loss function\n",
    "modelName1 = dataset + '_' + network1 + '_' + lossSel1 # the model Name to save the training neural network\n",
    "\n",
    "network2 = 'cunet'\n",
    "lossSel2 = 'DWBCE'\n",
    "modelName2 = dataset + '_' + network1 + '_' + network2 + '_' + lossSel2 + alpha\n",
    "\n",
    "#Variables about data preparation\n",
    "gtImgDict ={'MASS': '.tif', 'DeepGlobe': '.png'} #Set the format of the original images in the dataset                   \n",
    "nameSplitDict = {'MASS': '.', 'DeepGlobe': '_'} #for a pair of training image and test image: before the split sign, they should have same name\n",
    "nameSpliChar = nameSplitDict[dataset]     #'.' for MASS\n",
    "gtPosix   =  gtImgDict[dataset]           #'.tif' for MASS\n",
    "\n",
    "valOrTest = 'Test' #Test on the test dataset: valOrTest + 'X' and  valOrTest + 'Y'\n",
    "\n",
    "TrainXDir = rootDir + 'data/' + dataset + '/TrainX/'      #'../data/MASS/TrainX/'\n",
    "TrainYDir = rootDir + 'data/' + dataset + '/TrainY/'  #'../data/MASS/TrainY/'\n",
    "testXDir  = rootDir + 'data/' + dataset + '/' + valOrTest + 'X/'\n",
    "testYDir  = rootDir + 'data/' + dataset + '/' + valOrTest + 'Y/'\n",
    "\n",
    "sampleDir1 = rootDir + 'data/' + dataset + '/TrainSamples_SC' + str(sID) + '/'  #Save the extracted training samples into this file directory\n",
    "sampleDir2 = rootDir + 'data/' + dataset + '/TrainSamples_2SC' + str(sID) + '/'  #Save the extracted training samples into this file directory\n",
    "sampleDir22 = rootDir + 'data/' + dataset + '/TrainSamples_2SC' + str(sID) + '_' + modelName1 + alpha + '/'\n",
    "\n",
    "saveAsMat = False          #True: save all training samples in one numpy MAT; False: save each sample as a pair of png images\n",
    "maxNum = 2000000 #Upper limit of training samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0d1834",
   "metadata": {},
   "source": [
    "## Step 2. Generate training samples by data augmentation\n",
    "\n",
    "In our code, we generate the $sampleSize\\times sampleSize$ training samples(default 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a98ecd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated memory needed is: 0.0439453125\n",
      "45\n",
      "Total # of ORG images is: 3 [Current process on:  10078675_15 0 / 3\n",
      "Current image processing time is: 6.937661170959473\n",
      "Acc processing time is: 6.93766188621521\n",
      "Current process on:  10078690_15 1 / 3\n",
      "Current image processing time is: 6.870755195617676\n",
      "Acc processing time is: 13.80853796005249\n",
      "Current process on:  10078705_15 2 / 3\n",
      "Current image processing time is: 7.1399688720703125\n",
      "Acc processing time is: 20.94862174987793\n",
      "] , Complete\n",
      "(38, 512, 512, 3) (38, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "K = [2, 1, 1, 1, 2]  #Frequency of each random augmentation operations \n",
    "rotate = 5 \n",
    "#K[0]: randomly select K[0] training samples from trainX image\n",
    "#K[1], K[2]: flip trainX image from x, y axis respectively, then randomly select K[1] and K[2] training samples\n",
    "#K[3]: randomly darking the trainX, then randomly select K[3] training samples\n",
    "#K[4]: randomly rotate trainX image rotate times, then randomly select K[4] training samples from each rotated image\n",
    "#The function generate the training samples, generated samples are saved in saveDir\n",
    "genS.genTrainS4Seg(orgImgDir = TrainXDir , \n",
    "                       GTDir = TrainYDir, \n",
    "                       nameSpliChar = nameSpliChar,\n",
    "                       saveDir = sampleDir1, \n",
    "                       gtPosix = gtPosix, maxNum = maxNum, K = K, rotate = rotate, sampleSize = sampleSize, \n",
    "                       saveAsMat = saveAsMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efaf0c0",
   "metadata": {},
   "source": [
    "## Step 3. Define and training the nerual network in stage one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90d19ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for Stage 1 with model  MASS_dinknet34_DBCE on Data  ./data/MASS/TrainSamples_SC0/\n",
      "This is DinkNet34!\n",
      "The network parameters: 31.1 M\n",
      "Trainable parameters: 31.1 M\n",
      "Device is: cpu\n",
      "Save model will be:./models/MASS_dinknet34_DBCE_segmentor.pth\n",
      "the number of samples is: 41\n",
      "Begining training with  DBCE  loss function\n",
      "Epoch 0[--] train_losses =  0.82203 val_losses =  0.82759 val_IoU =  0.0 Time: 72.9\n",
      "total training time is: 72.9\n",
      "Epoch 1[--] train_losses =  0.79559 val_losses =  0.79464 val_IoU =  0.0 Time: 70.75\n",
      "total training time is: 143.65\n"
     ]
    }
   ],
   "source": [
    "print('Training for Stage 1 with model ', modelName1, 'on Data ', sampleDir1) \n",
    "#Define the neural network in stage one\n",
    "#Just for demo on cpu, batch_size and epochs are set to be small\n",
    "net1 = nt.getNetwork(network = network1, par = nt.Parameters(inputDim = 3))\n",
    "segNet = seg.segmentor(network = net1, inputDim = 3,  \n",
    "                       epochs = 2, batch_size = 4, learn_rate = 0.0001, \n",
    "                       early_patience = 10, lr_patience = 5, lr_factor = 0.98, \n",
    "                       lossSel = lossSel1)\n",
    "   \n",
    "segNet.TrainingD(sampleDir = sampleDir1, orgDir = sampleDir1, gtDir = sampleDir1, \n",
    "                     org_pos = '_sat.npy', gt_pos = '_mask.npy',\n",
    "                     ratio = 0.95, fileDir = rootDir + 'models/', fileName = modelName1, div = 2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6f9681",
   "metadata": {},
   "source": [
    "## Step 4. Test the nerual network in stage one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f84e417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading  ./models/MASS_dinknet34_DBCE_best_segmentor.pth  successfully!\n",
      "0 Process image: 10828720_15\n",
      "IoU =  0.0 Total number of test images is: 1\n",
      "The average statitisc measures are: \n",
      "IoU =  0.0  F1 =  0.0 prec =  0.0 recall =  0.0\n"
     ]
    }
   ],
   "source": [
    "saveDir  = rootDir + 'output/SegResult_' + dataset + '_' + modelName1 + '/'\n",
    "segNet.Loading(fileName = modelName1, fileDir = rootDir + 'models/', best = 1) #best = 1 Use the network with best validation loss\n",
    "ut.testGroupImages(segNet = segNet, groupDir = testXDir, groupGTDir = testYDir,\n",
    "                    nameSpliChar = nameSpliChar,\n",
    "                    gtImgType = gtPosix,\n",
    "                    saveDir  = saveDir, sampleS = sampleSize, stepW = -1, testMax = 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57ca1be",
   "metadata": {},
   "source": [
    "## Step 5. Generate training samples for stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "270b362a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate 2nd Stage samples from  ./data/MASS/TrainSamples_2SC0/  with  MASS_dinknet34_DBCE  save in  ./data/MASS/TrainSamples_2SC0_MASS_dinknet34_DBCE005/\n",
      "The estimated memory needed is: 0.0439453125\n",
      "45\n",
      "Total # of ORG images is: 3 [Current process on:  10078675_15 0 / 3\n",
      "Current image processing time is: 6.5128397941589355\n",
      "Acc processing time is: 6.5128419399261475\n",
      "Current process on:  10078690_15 1 / 3\n",
      "Current image processing time is: 6.786675930023193\n",
      "Acc processing time is: 13.299637079238892\n",
      "Current process on:  10078705_15 2 / 3\n",
      "Current image processing time is: 6.547276020050049\n",
      "Acc processing time is: 19.847028970718384\n",
      "] , Complete\n",
      "(41, 512, 512, 3) (41, 512, 512, 1)\n",
      "loading  ./models/MASS_dinknet34_DBCE_segmentor.pth  successfully!\n",
      "Total process samples: 43\n",
      "Begin generating: [----------------------] Finish generating with total time 21.82\n",
      "Avg IoU = 3.239422475761021e-06\n",
      "Total generated train number is:  43\n"
     ]
    }
   ],
   "source": [
    "print('Generate 2nd Stage samples from ', sampleDir2, ' with ', modelName1, ' save in ', sampleDir22)\n",
    "K = [2, 1, 1, 1, 2]      # We can set different augmentation operations\n",
    "rotate = 5 \n",
    "genS.genTrainS4Seg(orgImgDir = TrainXDir , \n",
    "                        GTDir = TrainYDir, \n",
    "                        nameSpliChar = nameSpliChar,\n",
    "                        saveDir = sampleDir2, \n",
    "                        gtPosix = gtPosix, maxNum = maxNum, K = K, rotate = rotate, sampleSize = sampleSize, \n",
    "                        saveAsMat = saveAsMat)\n",
    "    \n",
    "segNet.Loading(fileName = modelName1, fileDir = rootDir + 'models/', best = 0)  #Load the stage one nerual network\n",
    "genS.genRaw2ndStageTrainSamplesD(segNet, sampleDir2,  orgDir = sampleDir2, gtDir = sampleDir2, saveDir = sampleDir22, \n",
    "                                org_pos = '_sat.npy', gt_pos = '_mask.npy',\n",
    "                                XRName = 'SampleX_Raw', YRName = 'SampleY_Raw',\n",
    "                                netDir = rootDir + 'models/', sampleS = sampleSize, div = 20, testNum = 200000, \n",
    "                                wM = 1.0, wElse = 0.97, delta = delta, T_IoU = 0, saveAsMat = saveAsMat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fba3e0c",
   "metadata": {},
   "source": [
    "## Step 6. Define and training neural network in stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31539faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for Stage 2 with model  MASS_dinknet34_cunet_DWBCE005 on Data  ./data/MASS/TrainSamples_2SC0_MASS_dinknet34_DBCE005/\n",
      "This is CUNet!\n",
      "UNet LayerNumer is: 7\n",
      "The network parameters: 157.99 M\n",
      "Trainable parameters: 157.99 M\n",
      "Device is: cpu\n",
      "Save model will be:./models/MASS_dinknet34_cunet_DWBCE005_segmentor.pth\n",
      "the number of samples is: 43\n",
      "Begining training with  DWBCE  loss function\n",
      "Epoch 0[--] train_losses =  0.91194 val_losses =  0.88703 val_IoU =  0.01368 Time: 233.89\n",
      "total training time is: 233.9\n",
      "Epoch 1[--] train_losses =  0.86388 val_losses =  0.84216 val_IoU =  0.01424 Time: 238.58\n",
      "total training time is: 472.48\n"
     ]
    }
   ],
   "source": [
    "print('Training for Stage 2 with model ', modelName2, 'on Data ', sampleDir22)\n",
    "\n",
    "net2 = nt.getNetwork(network = network2, par = nt.Parameters(inputDim = 4, unet_nfilters = 32, unet_dropout = 0.08, unet_layerNum = 7))\n",
    "\n",
    "segNet2C = seg.segmentor(network = net2, inputDim = 4,  \n",
    "                       epochs = 2, batch_size = 4, learn_rate = 0.0001, \n",
    "                       early_patience = 10, lr_patience = 5, lr_factor = 0.98, \n",
    "                       lossSel = lossSel2, useMultiGPU = False)\n",
    "\n",
    "#segNet2C.Loading(fileName = modelName2, fileDir = rootDir + 'models/', best = 0)\n",
    "segNet2C.TrainingD(sampleDir = sampleDir22, orgDir = sampleDir22, gtDir = sampleDir22, \n",
    "                     org_pos = '_sat.npy', gt_pos = '_mask.npy',\n",
    "                     ratio = 0.95, fileDir = rootDir + 'models/', fileName = modelName2, div = 2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eca4b72",
   "metadata": {},
   "source": [
    "## Step 7. Test the 2 stage nerual networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab31928f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 2 Stage segmentation\n",
      "loading  ./models/MASS_dinknet34_DBCE_segmentor.pth  successfully!\n",
      "loading  ./models/MASS_dinknet34_cunet_DWBCE005_best_segmentor.pth  successfully!\n",
      "0 Process image: 10828720_15\n",
      "Result for stage 1:\n",
      "IoU =  0.0 Result for stage 2:\n",
      "IoU =  0.0515 Avg stage1 prediction time is: 12.38 3.09\n",
      "Avg stage2 prediction time is: 31.72 7.93\n",
      "Avg prediction time is: 44.1 11.02\n",
      "Total number of test images is: 1\n",
      "The average statitisc measures for stage 1 are: \n",
      "IoU =  0.0  F1 =  0.0 prec =  0.0 recall =  0.0\n",
      "The average statitisc measures for stage 2 are: \n",
      "IoU =  0.0515  F1 =  0.098 prec =  0.0515 recall =  1.0\n",
      "Total test time is: 44 2\n"
     ]
    }
   ],
   "source": [
    "print('Test 2 Stage segmentation')\n",
    "saveDir  = rootDir + 'output/SegResult_' + dataset + '_' + modelName1 + '_' + modelName2 + '/'   \n",
    "isSave = False #True, then save the test results; False: only calculate the evluation metrics\n",
    "segNet.Loading(fileName = modelName1, fileDir = rootDir + 'models/', best = 0)\n",
    "segNet2C.Loading(fileName = modelName2, fileDir = rootDir + 'models/', best = 1)\n",
    "time_s = time.time()\n",
    "ut.twoStageTestImages(segNet = segNet, segNet2 = segNet2C,\n",
    "                       groupDir = testXDir, groupGTDir = testYDir,\n",
    "                       nameSpliChar = nameSpliChar,\n",
    "                       gtImgType = gtPosix,\n",
    "                       saveDir  = saveDir, sampleS = sampleSize, stepW = -1, testMax = 10000,  T_o = 0, isSave = isSave)\n",
    "    \n",
    "print('Total test time is:', round(time.time() - time_s), 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MAD",
   "language": "python",
   "name": "mad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
